{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac013a59",
   "metadata": {},
   "source": [
    "# embedding-models\n",
    "\n",
    "embedding models embed the text into numeric representations of many dimensions and can be trained to serve a lot of purposes like sentiment classification, semantic understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66b8172",
   "metadata": {},
   "source": [
    "[Alt text](contrastive_learning.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62424a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to generate images with path specification required\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def imggen(im_path):\n",
    "    img=mpimg.imread(im_path)\n",
    "    plt.axis(\"off\")\n",
    "    return plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imggen('contrastive_learning.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af0dd65",
   "metadata": {},
   "source": [
    "## contrastive learning\n",
    "In order to accurately capture thesemantic nature of a document, it often needs to be contrasted with another\n",
    "document for a model to learn what makes it different or similar. \n",
    "\n",
    "\n",
    "so basically feeding the model with similar and dissimilar pairs..\n",
    "\n",
    "like instead of a question why P? we model it with contrast as why P and not Q? this makes it learn more info about the subject and \n",
    "ability to learn different features that make the subject unique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d27799e",
   "metadata": {},
   "source": [
    "### the best way to apply contrastive learning is through sentence- transformers\n",
    "\n",
    "\n",
    "\n",
    "# SBERT\n",
    "### (or sentence-BERT)\n",
    "1 LIMITATION OF BERT WAS the computational overhead because it uses a cross encoder and outputs 512*768 vector for a single sentence before similarity, either we use the [CLS] token that has a summary of the entire token embeddings but we still run a lot of compute in making those embeddings.\n",
    "\n",
    "We can also use Glove= global vectors for word representation; It’s not a neural network like BERT. It’s a matrix factorization method trained on global word co-occurrence statistics from a giant corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1a1a1d",
   "metadata": {},
   "source": [
    "### sentence transformers:\n",
    "\n",
    "uses 2 bert models parallely with tied weights, removes the classification head and brings in mean pooling over the token embeddings, to generate a final fixed size vector embedding which can later be used for similarity searches, compute is saved as we dont need to calculate with each sentence but only the ones in our query\n",
    "\n",
    "also, we concat the sentences embedded along with the difference in the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984eb3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imggen(\"sentra.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a49bd4",
   "metadata": {},
   "source": [
    "### creating an embedding model \n",
    "\n",
    "to create an embedding model we first need some contrastual data for training\n",
    "\n",
    "NLI natural language for inference provides where types of data for evaluation, one of them being mnli, that has premise and hypothesis pairs along with labels for contradiction, entailment or neutral relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f1568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imggen(\"mnli.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11491b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset nli dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset= load_dataset(\"glue\",\"mnli\", split='train').select(range(50_000))\n",
    "train_dataset= train_dataset.remove_columns(\"idx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaaf903",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.select_columns(['hypothesis', 'premise', 'label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3348a3bf",
   "metadata": {},
   "source": [
    "### Fixing TensorFlow Registry Error\n",
    "\n",
    "If you encounter the error \"Name tf.RaggedTensorSpec has already been registered\", restart the kernel before running the model training cells. This error occurs due to TensorFlow being imported multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad8bfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear TensorFlow registry and restart imports\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# Remove tensorflow modules if already imported\n",
    "modules_to_remove = [module for module in sys.modules.keys() if 'tensorflow' in module or 'keras' in module]\n",
    "for module in modules_to_remove:\n",
    "    del sys.modules[module]\n",
    "\n",
    "# Clear GPU memory if using GPU\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    tf.keras.backend.clear_session()\n",
    "    if tf.config.list_physical_devices('GPU'):\n",
    "        tf.config.experimental.reset_memory_growth(tf.config.list_physical_devices('GPU')[0])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"TensorFlow modules cleared. Ready for clean import.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eb9a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f03e896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86804e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training with proper type handling\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set environment variables to avoid conflicts\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Fix numpy int64 compatibility issues\n",
    "def fix_numpy_types():\n",
    "    import numpy as np\n",
    "    # Ensure numpy uses standard Python int types where needed\n",
    "    np.int64 = int\n",
    "\n",
    "\n",
    "try:\n",
    "    fix_numpy_types()\n",
    "    from sentence_transformers import SentenceTransformer, losses\n",
    "    \n",
    "    # Initialize the embedding model with error handling\n",
    "    embedding_model = SentenceTransformer('bert-base-uncased')\n",
    "    print(\"Model loaded successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    # Alternative approach if there are issues\n",
    "    try:\n",
    "        from transformers import AutoTokenizer, AutoModel\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        \n",
    "        # Try loading with explicit device mapping\n",
    "        embedding_model = SentenceTransformer('bert-base-uncased', device='cpu')\n",
    "        print(\"Model loaded on CPU successfully!\")\n",
    "        \n",
    "    except Exception as e2:\n",
    "        print(f\"Fallback loading also failed: {e2}\")\n",
    "        print(\"Please restart the kernel and try again.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd9294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#softmax losses\n",
    "from sentence_transformers import losses\n",
    "loss=losses.SoftmaxLoss(\n",
    "    \n",
    "    model=embedding_model,\n",
    "    sentence_embedding_dimension=embedding_model.get_sentence_embedding_dimension(),\n",
    "    num_labels=3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d8e2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding evaluation for the model, we use stsb or semantic textual similarity benchmark\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "val_sts=load_dataset(\"glue\",\"stsb\",split='validation')\n",
    "eval= EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_sts[\"sentence1\"],\n",
    "    sentences2=val_sts['sentence2'],\n",
    "    scores=[score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity=\"cosine\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d100f58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainingArguments\n",
    "from torch import bfloat16\n",
    "args=SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"base_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_eval_batch_size=4,\n",
    "    per_gpu_train_batch_size=4,\n",
    "   # float32=True, not for macs :(\n",
    "    eval_steps=100,\n",
    "    logging_steps=100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c74d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformerTrainer\n",
    "\n",
    "# trainer=SentenceTransformerTrainer(\n",
    "#     args=args,\n",
    "#     model=embedding_model,\n",
    "#     evaluator=eval,\n",
    "#     loss=loss,\n",
    "#     train_dataset=train_dataset\n",
    "\n",
    "# )\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc9c6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after training your model always remember to restart the notebook to make sure all vram is cleared up.\n",
    "#as the model is ded everytime we try to train it, we shift to colab notebook further training and use the trained model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2414cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "trained_model=SentenceTransformer(\"/Users/abhimanyu/Downloads/bert_base_trained_glue2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaa33a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences=[\"this is an example\",\"i am not the example\"]\n",
    "# embeddings=trained_model.encode(sentences)\n",
    "# print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d441079",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ec0201",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mteb is the state of the art library for evaluation of the model\n",
    "from mteb import MTEB\n",
    "    \n",
    "\n",
    "# Choose evaluation task with error handling\n",
    "# evaluation = MTEB(tasks=[\"Banking77Classification\"])\n",
    "\n",
    "# Calculate results with proper type handling\n",
    "\n",
    "import mteb\n",
    "\n",
    "tasks = mteb.get_tasks(tasks=[\"Banking77Classification\"])\n",
    "evaluation = MTEB(tasks=tasks)\n",
    "\n",
    "resultt = evaluation.run(trained_model)\n",
    "resultt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba3fa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mteb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "trained_model=SentenceTransformer(\"/Users/abhimanyu/Downloads/bert_base_trained_glue2\")\n",
    "\n",
    "\n",
    "tasks = mteb.get_tasks(tasks=[\"Banking77Classification\"])\n",
    "evaluation = MTEB(tasks=tasks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a55b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mteb\n",
    "\n",
    "# Fetch the Banking77Classification task object\n",
    "task = mteb.get_task(\"Banking77Classification\")\n",
    "\n",
    "# Get the dataset from the task object (usually stored in task.dataset or similar)\n",
    "dataset = task.dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9d6e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, inspect first few labels\n",
    "print(dataset['validation'][:5])  # or dataset['validation'][:5]\n",
    "\n",
    "# Or print types of labels (adjust key if needed)\n",
    "labels = dataset['train']['label']\n",
    "print([type(label) for label in labels[:10]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fdce54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(tasks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5dba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(task.dataset)  # May be None or a complex object\n",
    "from mteb import get_task\n",
    "\n",
    "task = get_task(\"Banking77Classification\")\n",
    "\n",
    "print(task.splits)  # List available splits\n",
    "print(task.get_dataset(split=\"train\"))  # Load train split properly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b653564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mteb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Define the sentence-transformers model name\n",
    "model_name = (\"/Users/abhimanyu/Downloads/bert_base_trained_glue2\")\n",
    "\n",
    "model = mteb.get_model(model_name) # will default to SentenceTransformers(model_name) if not implemented in MTEB\n",
    "tasks = mteb.get_tasks(tasks=[\"STSBenchmark\"])\n",
    "evaluation = mteb.MTEB(tasks=tasks)\n",
    "results = evaluation.run(model,output_folder=\"results/STSBenchmark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef45fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#   \"dataset_revision\": \"b0fddb56ed78048fa8b90373c8a3cfc37b684831\",\n",
    "#   \"evaluation_time\": 5.260719060897827,\n",
    "#   \"kg_co2_emissions\": null,\n",
    "#   \"mteb_version\": \"1.12.39\",\n",
    "#   \"scores\": {\n",
    "#     \"test\": [\n",
    "#       {\n",
    "#         \"cosine_pearson\": 0.5660132977293474,\n",
    "#         \"cosine_spearman\": 0.6237134696545672,\n",
    "#         \"euclidean_pearson\": 0.6112715246993904,\n",
    "#         \"euclidean_spearman\": 0.6307245433589723,\n",
    "#         \"hf_subset\": \"default\",\n",
    "#         \"languages\": [\n",
    "#           \"eng-Latn\"\n",
    "#         ],\n",
    "#         \"main_score\": 0.6237134696545672,\n",
    "#         \"manhattan_pearson\": 0.6205697391835063,\n",
    "#         \"manhattan_spearman\": 0.6330864771670663,\n",
    "#         \"pearson\": [\n",
    "#           0.5660132935950654,\n",
    "#           1.2533873237354529e-117\n",
    "#         ],\n",
    "#         \"spearman\": [\n",
    "#           0.6237134696545672,\n",
    "#           1.6490706502858626e-149\n",
    "#         ]\n",
    "#       }\n",
    "#     ]\n",
    "#   },\n",
    "#   \"task_name\": \"STSBenchmark\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed401d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "train_datasets=load_dataset(\"glue\",\"mnli\",split=\"train\").select(range(50_000))\n",
    "\n",
    "train_datasets=train_datasets.remove_columns(\"idx\")\n",
    "\n",
    "mapping={2:0,1:0,0:1}\n",
    "train_datasets=Dataset.from_dict({\n",
    "    \"sentence1\":train_datasets[\"premise\"],\n",
    "    \"sentence2\":train_datasets[\"hypothesis\"],\n",
    "    \"labels\": [float(mapping[label]) for label in train_datasets[\"label\"]]\n",
    "})\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "# Load MNLI dataset from GLUE\n",
    "# 0 = entailment, 1 = neutral, 2 = contradiction\n",
    "train_dataset = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(50_000))\n",
    "train_dataset = train_dataset.remove_columns(\"idx\")\n",
    "\n",
    "# (neutral/contradiction)=0 and (entailment)=1\n",
    "mapping = {2: 0, 1: 0, 0:1}\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": train_dataset[\"premise\"],\n",
    "    \"sentence2\": train_dataset[\"hypothesis\"],\n",
    "    \"label\": [float(mapping[label]) for label in train_dataset[\"label\"]]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32491f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fce8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create an evaluater\n",
    "# from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "# val_sts=load_dataset(\"glue\",\"stsb\",split=\"validation\")\n",
    "# val_evaluator= EmbeddingSimilarityEvaluator(\n",
    "#     sentences1=val_sts[\"sentence1\"],\n",
    "#     sentences2=val_sts[\"sentence2\"],\n",
    "#     scores=[score/5 for score in val_sts[\"label\"]],\n",
    "#     main_similarity=\"cosine\",\n",
    "# )\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "# Create an embedding similarity evaluator for stsb\n",
    "val_sts = load_dataset('glue', 'stsb', split='validation')\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_sts[\"sentence1\"],\n",
    "    sentences2=val_sts[\"sentence2\"],\n",
    "    scores=[score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity=\"cosine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcd6383",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ca0056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, losses\n",
    "from sentence_transformers import SentenceTransformerTrainer\n",
    "from sentence_transformers import SentenceTransformerTrainingArguments\n",
    "\n",
    "embedding_model= SentenceTransformer('bert-base-uncased')\n",
    "train_loss= losses.CosineSimilarityLoss(model=embedding_model)\n",
    "\n",
    "args= SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"cosineloss_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4abbbb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a081912",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer=SentenceTransformerTrainer(\n",
    "    args=args,\n",
    "    model= embedding_model,\n",
    "    evaluator=evaluator,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss    \n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd17d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
